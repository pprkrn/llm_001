import csv
import os
import re
import time
from llm_query import data_for_csv
from webscrape_imprint import domain
#import subprocess


#subprocess.run(['python', 'webscrape_imprint.py'])
#subprocess.run(['python', 'llm_query.py'])


# ğŸ“ CSV-Datei vorbereiten
csv_file = "impressum_analyse_debug.csv"
csv_header = ["Unternehmensname", "GeschÃ¤ftsfÃ¼hrer", "E-Mail-Adresse", "Telefonnummer", "Adresse", "HRB-Nummer", "UStID-Nummer", "Website"]

# ğŸ§¾ Input-Variable aus anderem Modul
input_string = data_for_csv

# ğŸ” Funktion zum Extrahieren der Infos (Website kommt aus 'domain')
def extract_info(text, domain):
    def extract(pattern):
        match = re.search(pattern, text)
        return match.group(1).strip() if match else "N/A"

    return {
        "Unternehmensname": extract(r"\*\*Unternehmensname:\*\*\s*(.+)"),
        "GeschÃ¤ftsfÃ¼hrer": extract(r"\*\*GeschÃ¤ftsfÃ¼hrer:\*\*\s*(.+)"),
        "E-Mail-Adresse": extract(r"\*\*E-Mail-Adresse:\*\*\s*(.+)"),
        "Telefonnummer": extract(r"\*\*Telefonnummer:\*\*\s*(.+)"),
        "Adresse": extract(r"\*\*Adresse:\*\*\s*(.+)"),
        "HRB-Nummer": extract(r"\*\*HRB-Nummer:\*\*\s*(.+)"),
        "UStID-Nummer": extract(r"\*\*UStID-Nummer:\*\*\s*(.+)"),
        "Website": domain
    }

# ğŸ“¦ Daten extrahieren
eintrag = extract_info(input_string, domain)

# ğŸ“ Datei Ã¶ffnen und ggf. Header schreiben
file_exists = os.path.isfile(csv_file)

with open(csv_file, mode='a', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=csv_header)
    if not file_exists:
        writer.writeheader()
    writer.writerow(eintrag)